{"config":{"lang":["en"],"separator":"[\\s\\-\\_]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Internet of Things - From Scratch!","text":"<p>Or, how to build your own smart home based around a microservice architecture.</p>"},{"location":"#what-is-this","title":"What Is This?","text":"<p>This book is a guide for building your own IoT (or Smart Home, etc) Infrastructure using MQTT and a collection of services. Think of it as the Smart Home equivalent of Linux From Scratch.</p>"},{"location":"#why-would-i-want-to-build-my-own-iot","title":"Why Would I want To Build My Own IoT?","text":"<p>There are many reasons people decide to build their own smarthome infrastructure:</p> <ul> <li>Learning- It's a great way to learn about microservice architectures and how to run them.</li> <li>Reliability- You want a system that you can make as reliable and resiliant as possible.</li> <li>Security- Because that's what the S in IoT stands for.</li> <li>Control- You want to control exactly what runs in your home, not turn it over to Big Tech.</li> </ul>"},{"location":"#why-dont-you-use-homeassistantopenhabiobrokeretc","title":"Why don't you use HomeAssistant/openHAB/ioBroker/etc?","text":"<p>Those are fine tools. In fact, they might be a part of your IoT-FS setup in some capacity! This book is not about foregoing those tools, but about building an IoT platform that is specific to you.</p>"},{"location":"#how-do-i-use-this-book","title":"How Do I Use This Book?","text":"<p>In the top bar of this site you'll see links directly to each chapter. On the left (or in the hamburger menu if you have a narrow browser) you will find links to each page of the current chapter. There are also links to the previous and next page at the bottom you can use to navigate.</p> <p>You are encouraged to read through the entire book, or at least skim the first few paragraphs of each page, before you start building. Each chapter builds on the last and you may find yourself lost if you skip ahead. Once you have an idea of how it all fits together you'll find yourself coming back to reread specific chapters and pages.</p>"},{"location":"vestigal/","title":"Vestigal","text":""},{"location":"vestigal/#step-2-deploy-mqtt","title":"Step 2- Deploy MQTT","text":"<p>Literally everything you want to deploy will depond on this infrastructure. Give it the attention its due on setup and you'll never have to worry about it again.</p> <p>You'll need to pick a broker. There are a lot of them available. However, almost everyone uses Mosquitto, and you should too unless you have a very good reason.</p> <p>Follow this checklist to make sure you've done everything:</p> <ul> <li>Install Mosquitto</li> <li>Test to make sure it works</li> <li>Setup authentication</li> <li>Setup SSL/TLS</li> </ul>"},{"location":"vestigal/#step-3-metrics-and-visualization","title":"Step 3- Metrics and Visualization","text":"<p>Optional but very helpful.</p> <p>Find yourself a graphing system you like and deploy it. There are lots to choose from.</p> <ul> <li>graphite- easy to get going, outdated UI, can be hard to get some features working</li> <li>influxdb- successor to graphite, v2 is harder to setup and less open source friendly</li> <li>prometheus- docker/k8s darling</li> </ul>"},{"location":"vestigal/#step-4-logs","title":"Step 4- Logs","text":"<p>Optional but very helpful.</p> <p>You'll want to be able to look at logs, and there are systems that can make searching them across your cluster easier. If you only have a single machine it's very managable to only use the Docker and Systemd logging facilities, but as your infrastructure grows these systems will grow with you:</p> <ul> <li>ELK</li> <li>Graylog</li> <li>Fluentd</li> </ul>"},{"location":"vestigal/#step-5-deploy-your-first-app","title":"Step 5- Deploy your first app","text":"<p>This is where you'll deploy your first microservice. You probably have some hardware you're looking at using, here are some good choices for first applications to deploy:</p> <ul> <li>zwavejs2mqtt</li> <li>zigbee2mqtt</li> <li>homebridge</li> <li>esphome</li> <li>tasmota</li> </ul>"},{"location":"vestigal/#step-6-deploy-more-apps","title":"Step 6- Deploy more apps","text":"<p>Now that you've deployed one application it's time to build on your foundation. Deploy more apps until all the hardware you want to monitor and/or control is working on MQTT.</p>"},{"location":"vestigal/#step-7-iterate","title":"Step 7- Iterate","text":"<p>At this point you should have a good handle on where to go from here. Iterate until you're happy with your system, if you can ever be happy. :)</p>"},{"location":"infrastructure/","title":"Infrastructure","text":"<p>Infrastructure is the physical hardware and service management software you use to deploy your microservices. In this chapter we'll cover the recommended options and point you towards resources for using them.</p>"},{"location":"infrastructure/docker-compose/","title":"Docker Compose","text":"<p>Docker Compose is the standard way to manage services using Docker. While it is focused on defining and running multi-container applications it also works well for managing the configuration of single-container applications. See the official documentation for a more in-depth explanation.</p>"},{"location":"infrastructure/docker-compose/#why-would-you-want-to-use-docker-compose","title":"Why Would You Want To Use Docker Compose?","text":"<p>When you first start out you may wonder why you want to go to this extra work. You can just launch containers directly and they stay running, and all my services are simple. What benefit does this provide?</p> <p>The answer to that question will come in a few days, weeks, or months, when you are ready to change your system. When it's time to <code>docker pull</code> a new upstream container you will have to destroy and recreate the container. Will you remember every argument you passed the first time? What happens if you have a drive failure and you have to rebuild everything?</p> <p>With a proper Docker Compose setup you don't have to worry about any of that, because your exact configuration will be documented in <code>docker-compose.yml</code> files.</p>"},{"location":"infrastructure/docker-compose/#structure-for-your-docker-compose-infrastructure","title":"Structure For Your Docker Compose Infrastructure","text":"<p>While it is possible to work with multiple <code>docker-compose.yml</code> files within the same directory, most people find it easier to build a directory tree to store their services and configuration. This allows for a lot of flexibility when it comes to building and managing your services. There are many ways you manage these files, but this is what we recommend for maximum flexibility and ease of use.</p>"},{"location":"infrastructure/docker-compose/#basic-setup","title":"Basic setup","text":"<p>First, pick a home for your directory tree. This can be anywhere, but in most situations we recommend <code>/srv/docker</code>. For the rest of this guide we will assume you have placed your directory tree there.</p> <pre><code>sudo mkdir -p /srv/docker-compose\nsudo chown `whoami` /srv/docker-compose  # Optional, but makes\n# it easier to manage\n</code></pre> <p>Within this directory you will create directories for every service you want to run.</p> <p>Note</p> <p>The term \"service\" here is used in a slightly different way than you may be used to. In this context a service is any collection of one or more containers. Each container runs a single daemon process, which is what you may be used to thinking of as a service.</p>"},{"location":"infrastructure/docker-compose/#create-your-first-service","title":"Create Your First Service","text":"<p>Let's start by setting up a service for the Mosquitto MQTT broker. This will demonstrate setting up a simple service which someone else has published a container for.</p> <p>First we'll create directories for it. Notice that we have created a directory in <code>/srv/docker-compose</code> and directories for volume mounts in <code>/srv/mosquitto</code>. If you are setting up a service that doesn't need volume mounts you can skip that.</p> <pre><code>mkdir -p /srv/docker-compose/mosquitto /srv/mosquitto/conf /srv/mosquitto/data /srv/mosquitto/log\n</code></pre> <p>Create the <code>/srv/docker-compose/mosquitto/docker-compose.yml</code> file:</p> <p>/srv/docker-compose/mosquitto/docker-compose.yml</p> <pre><code>version: \"3\"\nservices:\n  mosquitto:\n    image: eclipse-mosquitto\n    volumes:\n      - ./conf:/mosquitto/conf\n      - ./data:/mosquitto/data\n      - ./log:/mosquitto/log\n    ports:\n      - 1883:1883\n      - 9001:9001\n</code></pre> <p>Create the <code>mosquitto.conf</code> configuration file:</p> <p>/srv/mosquitto/conf/mosquitto.conf</p> <pre><code>persistence true\npersistence_location /mosquitto/data/\nlog_dest file /mosquitto/log/mosquitto.log\n\nlistener 1883\n</code></pre> <p>Once this is in place you can use <code>docker-compose</code> to bring it up:</p> <pre><code>cd /srv/docker-compose/mosquitto\ndocker-compose up --detach\n</code></pre> <p>If you want to watch the logs you can attach to them like this:</p> <pre><code>cd /srv/docker-compose/mosquitto\ndocker-compose logs\n</code></pre> <p>To bring the service down:</p> <pre><code>cd /srv/docker-compose/mosquitto\ndocker-compose down\n</code></pre>"},{"location":"infrastructure/docker-compose/#custom-docker-containers","title":"Custom Docker Containers","text":"<p>Sometimes you need to customize a container before it gets deployed. Docker provides a mechanism for doing so using <code>Dockerfile</code>. We'll demonstrate how to do that by creating a custom nginx service.</p> <p>As before we need to create the docker-compose directory:</p> <pre><code>mkdir -p /srv/docker-compose/nginx/nginx\n</code></pre> <p>Notice that we did not include a data directory in <code>/srv</code>, and we added an extra <code>/nginx</code> to the end of our path? The first <code>nginx</code> path component refers to the service, while the second <code>nginx</code> path component refers to the container.</p> <p>Now we create the <code>docker-compose.yml</code> file:</p> <p>/srv/docker-compose/nginx/docker-compose.yml</p> <pre><code>version: '3'\nservices:\n  nginx:\n    build: ./nginx\n    ports:\n      - \"80:80\"\n</code></pre> <p>This is where the second nginx directory comes into play- we are going to create a <code>Dockerfile</code> and an <code>index.html</code> inside of there.</p> <p>/srv/docker-compose/nginx/nginx/Dockerfile</p> <pre><code>FROM nginx:mainline\nCOPY index.html /usr/share/nginx/html\n</code></pre> <p>/srv/docker-compose/nginx/nginx/index.html</p> <pre><code>&lt;h1&gt;Hello, World!&lt;/h1&gt;\n</code></pre> <p>With these two files in place you are ready to start nginx:</p> <pre><code>cd /srv/docker-compose/nginx\ndocker-compose up --detach\n</code></pre>"},{"location":"infrastructure/docker-compose/#writing-your-own-service","title":"Writing Your Own Service","text":"<p>Now we'll look at a more complex example- we'll implement our own service along with the infrastructure it needs. In this example we'll stub out an application that uses a redis backend. As before, we start by creating the directories we need:</p> <pre><code>mkdir -p /srv/docker-compose/my_cool_app/my_cool_app\n</code></pre> <p>Create some files:</p> <p>/srv/docker-compose/my_cool_app/docker-compose.yml</p> <pre><code>version: '3'\nservices:\n  my_cool_app:\n    build: ./nginx\n    ports:\n      - \"80:80\"\n  redis:\n    image: redis:latest\n    ports:\n      - \"6379:6379\"\n    restart: always\n</code></pre> <p>/srv/docker-compose/my_cool_app/my_cool_app/Dockerfile</p> <pre><code>FROM debian:stable\nCOPY my_cool_app /\nENTRYPOINT [\"/my_cool_app\"]\n</code></pre> <p>/srv/docker-compose/my_cool_app/my_cool_app/my_cool_app</p> <pre><code>#!/usr/bin/env python3\nimport time\nprint('Hello, World!')\nwhile True:\n    sleep(0.1)\n</code></pre> <p>With these files in place you're ready to run your service. There are two ways you can run it:</p> <p>Development mode:</p> <p>Use this while you are actively developing the app. Logs for all services will display on STDOUT and pressing ^C will stop all the containers.</p> <pre><code>cd /srv/docker-compose/my_cool_app\ndocker-compose down  # This ensures that you have a fresh start\ndocker-compose up\n</code></pre> <p>Production mode:</p> <p>Use this when you want your service to run normally, even after you logout.</p> <pre><code>cd /srv/docker-compose/my_cool_app\ndocker-compose down  # This ensures that you have a fresh start\ndocker-compose up --detach\n</code></pre>"},{"location":"infrastructure/docker-kubernetes/","title":"Server(s) Using Kubernetes","text":"<p>Kubernetes, or K8s, is an open-source system for automating deployment, scaling, and management of containerized applications. What does that mean? It will manage your containers for you. Virtually every company that uses containers has settled on K8s as the way to manage the deployment and lifecycle of their applications.</p> <p>Should you use K8s for your IoT-FS infrastructure? Ye, if you want to learn K8s. If you're not interested in learning k8s there's not much reason to set it up. There is a lot of work that goes into installing and using K8s, and you will have a lot of concepts to learn. If you are running a handful of services that you never have to scale, which is by far the most common IoT-FS situation, the sweet spot is one or two servers running Docker with Docker Compose.</p>"},{"location":"infrastructure/docker/","title":"Docker on a Server","text":"<p>While it's possible to wrangle services on a single machine, often you will run into conflict between services. Enter Docker- the easy way to keep your apps separate without the pain and overhead of traditional virtualization. This is an easy upgrade for any basic Linux server, and in fact you can start using Docker without disturbing your current services.</p> <p>To get started just install docker for your platform.</p>"},{"location":"infrastructure/docker/#docker-on-linux","title":"Docker on Linux","text":"<p>Your distribution may ship with docker already. This will work perfectly fine in most cases, but you may want to use docker-ce instead to have the latest version.</p>"},{"location":"infrastructure/docker/#docker-on-macos","title":"Docker on macOS","text":"<p>If you use homebrew you can install docker with a simple <code>brew install docker</code>.</p>"},{"location":"infrastructure/docker/#docker-on-windows","title":"Docker on Windows","text":"<p>On Windows you will need to use Docker Desktop.</p>"},{"location":"infrastructure/hardware/","title":"Hardware","text":"<p>You'll need at least one computer to run your IoT-FS infrastructure on. The base requirements to get started are surprisingly small. You may also choose to have multiple computers for performance or redundancy purposes. There's really a wide range of possibilities, and what you choose will depend a lot on your needs.</p>"},{"location":"infrastructure/hardware/#capacity-planning","title":"Capacity Planning","text":"<p>You'll want to do some basic capacity planning to know whether your system can handle your planned load. Here are some things to keep in mind when doing that.</p> <ul> <li>Mosquitto consumes around 100mb RAM.</li> <li>Each python service consumes at least 15mb RAM, but more likely consumes closer to 50mb of RAM.</li> <li>With proper log rotation my stored data is less than 1gb.</li> <li>Homebridge can consume a lot of RAM, depending on how many plugins you run. I regularly see 150mb+.</li> <li>If you add HomeAssistant, openHab, or other \"all-in-one\" systems your footprint will significantly increase.</li> <li>If you want to record video, especially with motion detection, your footprint will dramatically increase.</li> </ul> <p>In general if your system has at least 2gb of RAM and 64gb of storage you will be just fine, but list out your planned services and the expected RAM and Disk usage to sanity check this assumption.</p>"},{"location":"infrastructure/hardware/#hardware-choices","title":"Hardware Choices","text":"<p>Almost any hardware is usable for IoT-FS, from a lowly Raspberry Pi running at 1GHz all the way up to a multi-processor Xeon running at 3.5GHz. As such this is what we recommend you use, ordered from strongest to weakest suggestion.</p> <ol> <li>Whatever you have laying around<ul> <li>The main benefit of choosing this solution is that you can use anything you have available, such as a Raspberry Pi, old computer, etc.</li> <li>All you have to do is install the Linux distribution of your choice.</li> </ul> </li> <li>The computer you're using right now<ul> <li>Docker is available for all major OSes</li> </ul> </li> <li>A Raspberry Pi<ul> <li>At only $15 a Pi Zero is the least expensive way to get started</li> <li>The value of a $35 Pi 4 is hard to beat</li> </ul> </li> <li>A PC built to your specifications<ul> <li>There are PCs available at nearly every price point, you can source or build one that meets your exact needs.</li> </ul> </li> </ol>"},{"location":"infrastructure/hardware/#reliability-considerations","title":"Reliability Considerations","text":"<p>The reliability of your system starts with hardware. You want a system that won't randomly lock up due to hardware faults, and you want to protect your data in the event of drive failures. While not strictly necessary, consider using multiple smaller drives over one larger drive, and prefer RAID1 and RAID5/6. Never use RAID0! You are doubling the chance of losing your data with each new drive you add.</p>"},{"location":"infrastructure/hardware/#raspberry-pi-and-other-sd-card-systems","title":"Raspberry Pi and other SD Card systems","text":"<p>You never want to run your IoT-FS on SD cards, they do not hold up to the repeated writes. If you plan to use a system that boots from an SD card consider the following recommendations:</p> <ul> <li>Mount /var/log and other locations that are written to regularly to a RAM disk</li> <li>Install fast USB3 SSDs and run the system off that instead</li> <li>Deploy multiple systems and use a clustered FS like Gluster or Ceph</li> </ul>"},{"location":"infrastructure/linux/","title":"Linux","text":"<p>Linux is the most popular server OS in the world. There are many distributions to pick from and nearly all of them can run Docker. We recommend you use Linux for your IoT-FS project because you can be guaranteed that pretty much everything you want to run will work on it.</p>"},{"location":"infrastructure/linux/#what-linux-distribution-should-i-use","title":"What Linux Distribution Should I Use?","text":"<p>If you're just starting out and have no idea what to use, pick the latest Ubuntu LTS release. Ubuntu is popular and well known, and you will be able to find lots of help for it.</p> <p>If you have a favorite Linux distribution already use that. Likewise, if your employer has a distribution they use pick that one instead. This will help you learn the tools you use at work.</p>"},{"location":"overview/","title":"Introduction","text":"<p>This chapter will give you a broad overview of how to build your IoT-FS smart home.</p> <p>Building your own self-hosted IoT infrastructure is both easier than you think and more work than you think. You will be learning a lot of concepts and managing a lot of software, most of which you won't have a good understanding of. At this point you're probably thinking one of two things-</p> <ul> <li>\"Ugh, this is too much work.\"</li> <li>\"Wow, that's a lot of opportunity for learning!\"</li> </ul> <p>If you're able, I encourage you to focus on the learning aspect. You will have a lot of that to do, and some of it will come in the form of making mistakes. My hope in writing this book is that you will make your own mistakes, not repeat mine.</p> <p>To find success you will need to do your own deep diving from time to time. Do not be afraid to seek out documentation, videos, and other support and knowledge while you work on your IoT-FS project.</p>"},{"location":"overview/#target-audience","title":"Target Audience","text":"<p>This book assumes you already have a basic understand of developing software in at least one programming language. You should already be familiar with concepts like editing plain text files, writing structured files like JSON and YAML, and using HTTP or other network protocols. You don't need to know any language in particular, you can run someone else's code without knowing the programming language, and you can write your own services in whatever language you want.</p> <p>If your current or desired job title is on this list, IoT-FS is an excellent way to develop your skills and build a portfolio of personal projects to show off.</p> <ul> <li>Programmer</li> <li>Software Engineer</li> <li>DevOps</li> <li>Site Reliability Engineer</li> <li>Infrastructure/Platform Engineer</li> </ul>"},{"location":"overview/containers/","title":"Containers","text":"<p>In recent years containers have become the preferred way to deploy software at scale. Docker Containers are the most widely used, but all container technology shares the same basic premise- the userland of the OS is the deployable unit. When you launch a container it does not run in the host OS, but in a self-contained and isolated environment. Every tool, library, and configuration file available to your service is bundled together and deployed as a single unit.</p> <p>This decouples your applications from one another, and from the host OS. You will be able to install applications with conflicting dependencies side by side, because each application will deploy its own files. You can still share files and other resources between applications if necessary, but those applications can be running on wildly different software stacks.</p>"},{"location":"overview/infrastructure/","title":"Infrastructure","text":"<p>Infrastructure is the physical hardware and service management software you use to deploy your microservices. There are a lot of choices here, and what you pick will mostly depend on what you want to learn. There is a wide variety of hardware to pick from as well, such as compact PCs, server PCs, and Raspberry Pi.</p> <p>Whatever hardware you choose you will need an operating system as well. This book assumes you will dedicate at least one computer to this project and focuses on using Linux and Docker on those computer(s). As such it doesn't matter which Linux distribution you choose, most of your work will happen on a layer above.</p> <p>We chose Docker because it is well known and used in a plurality of environments. There are other container and virtualization solutions out there, and if they meet your needs better you can use them.</p>"},{"location":"overview/microservices/","title":"Microservices","text":"<p>Microservices, also known as the Microservice Architecture Pattern, is a way to build complex applications out of many self-contained services. It often sits at the opposite end of the spectrum from the Monolithic Architecture Pattern, where the application lives entirely in a single service. There is nothing wrong with following either pattern, but this guide focuses on microservices for two main reasons:</p> <ol> <li>You are able to leverage existing home automation microservices that have been released as open source.</li> <li>It breaks your project down into friendly weekend sized pieces.</li> </ol> <p>Most IoT-FS projects are neither pure microservices or pure monolithic. You will have some small and focused services, and others that end up growing beyond their original scope in significant ways. Do not fear this possibility, but rather accept it as the invevitable result of healthy growth. It will gives you an opportunities to identify when it's time to split a service up, or to combine two services that do that very similar things. </p> <p>Working through those challenges will make you a better engineer.</p>"},{"location":"overview/mqtt/","title":"MQTT","text":"<p>MQTT is the core infrastructure you will build your IoT-FS around. It is a lightweight message transport that you will both read from and publish to. Clients connect to the MQTT server to send and/or receive messages from other clients connected to the same server.</p> <p>When a client sends a message to MQTT it contains two important pieces of information, the <code>topic</code> and the <code>payload</code>. In the diagram below we show a temperature sensor publishing a reading. The topic is the <code>bedroom/sensor/bedroom_temperature</code> part, while the payload is <code>22.8</code>. The clients on the right have subscribed to the topic for this sensor and as such will receive a copy of the message.</p> <p></p>"},{"location":"overview/mqtt/#mqtt-topics","title":"MQTT Topics","text":"<p>The topic is how the MQTT server routes messages. Clients subscribe to one or more topics and the MQTT server routes all matching messages to those clients. Topics are similar to file paths, they are slash (<code>/</code>) separated strings that indicate unique resources. Here are some examples of topics I see on my MQTT server:</p> <ul> <li><code>homeassistant/binary_sensor/Kitchen-FrontdoorDetector/contact/config</code></li> <li><code>weather/daily/0/temp/day_C</code></li> <li><code>rtl_433/7b85b6eafe6d/devices/Acurite-Tower/A/9181/temperature_C</code></li> <li><code>zwave/Kitchen/FrontdoorDetector/113/0/Access_Control/Door_state</code></li> </ul> <p>As you can see there is a structure to MQTT topics, but that structure is not always well defined or consistent between services.</p>"},{"location":"overview/mqtt/#wildcards","title":"Wildcards","text":"<p>When subscribing to MQTT topics the client can utilize wildcards. This allows the client to subscribe to multiple topics easily, or even to listen on every topic. The available wildcards are:</p> <ul> <li><code>+</code>: Similar to the <code>*</code> wildcard in shell, this matches any string contained between topic parts (Denoted by the slash (<code>/</code>) character.)</li> <li><code>#</code>: This is similar to <code>+</code>, but it will match against all following topic parts as well.</li> </ul> <p>Some examples:</p> <ul> <li><code>+/sensor/+</code>: Subscribe to all of the esphome sensors, which are always in the format <code>&lt;room&gt;/sensor/&lt;room&gt;_&lt;sensor&gt;</code></li> <li><code>homeassistant/#</code>: Subscribe to the Home Assistant MQTT Discovery topics</li> <li><code>#</code>: Subscribe to everything</li> </ul>"},{"location":"overview/mqtt/#mqtt-payloads","title":"MQTT Payloads","text":"<p>To the MQTT server a payload is just an array of bytes. It delivers this payload exactly as it was received, it's up to the client to correctly decode the payload. In practice payloads are almost always ASCII or UTF-8 encoded text, even when dealing with numeric data.</p> <p>(Note: In MQTT 5 there is new metadata to indicate the payload's format and content type. We are focusing on MQTT 3 for now as it is the most widely-deployed protocol.)</p> <p>Some applications use single-value payloads. These payloads are typically strings or simple ints or floats encoded as strings. Some applications encode their payload using JSON to allow for more complex data to be sent. Neither pattern is right or wrong, they simply grew out of the requirements of the application.</p>"},{"location":"overview/mqtt/#quality-of-service","title":"Quality Of Service","text":"<p>Messages sent to MQTT are (usually) delivered to clients in the order they are received. If your connection to the server is stable they will always be in order. If your connection is not stable it will depend on the Quality Of Service (QOS) level set:</p> <ul> <li><code>QOS=0</code>: the message may not get delivered</li> <li><code>QOS=1</code>: the message may get delivered more than once</li> <li><code>QOS=2</code>: the message will get delivered exactly once</li> </ul> <p>It's not important to understand the difference between these right now, it's enough to know that you can choose the level of reliability to match your application's needs.</p>"},{"location":"overview/mqtt/#mqtt-standards","title":"MQTT Standards","text":"<p>As you can tell MQTT allows for a broad range of usage patterns. There have been two attempts to standardize these patterns that are worth your time to read:</p> <ul> <li>mqtt-smarthome</li> <li>The Homie Convention </li> </ul> <p>As you read these keep in mind that neither standard has been widely adopted.</p>"}]}